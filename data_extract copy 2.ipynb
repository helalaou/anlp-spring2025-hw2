{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/8z/p7vsmby10hscrk6290gzfnnr0000gn/T/ipykernel_39734/3194386972.py\", line 12, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/core/ops/__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/core/ops/array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/core/computation/expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/core/computation/check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/numexpr/__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/8z/p7vsmby10hscrk6290gzfnnr0000gn/T/ipykernel_39734/3194386972.py\", line 12, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/arrow/array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/Users/tianyicheng/anaconda3/lib/python3.11/site-packages/bottleneck/__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "from urllib.parse import urlparse, urljoin\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pdfplumber\n",
    "from docx import Document\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, save_dir=\"downloaded_files\"):\n",
    "    \"\"\"Downloads a file from a URL and saves it locally.\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Ensure directory exists\n",
    "    filename = os.path.join(save_dir, os.path.basename(urlparse(url).path))\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(filename, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            return filename\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_text_from_html(url):\n",
    "    \"\"\"Extracts text from an HTML webpage.\"\"\"\n",
    "    try:\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        text = \"\\n\".join([p.get_text(strip=True) for p in soup.find_all(\"p\")])\n",
    "        return text.strip() if text else None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    try:\n",
    "        text = \"\"\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "        \n",
    "        print(f\"text: {text}\")\n",
    "        return text.strip() if text else None\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def extract_text_from_docx(file_path):\n",
    "    \"\"\"Extracts text from a DOCX file.\"\"\"\n",
    "    try:\n",
    "        doc = Document(file_path)\n",
    "        text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "        return text.strip() if text else None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def extract_text_from_excel(file_path):\n",
    "    \"\"\"Extracts text from an Excel file (reads all sheets).\"\"\"\n",
    "    try:\n",
    "        text = \"\"\n",
    "        xls = pd.ExcelFile(file_path)\n",
    "        for sheet_name in xls.sheet_names:\n",
    "            df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "            text += df.to_string(index=False) + \"\\n\"\n",
    "        return text.strip() if text else None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def extract_text_from_plaintext(file_path):\n",
    "    \"\"\"Extracts text from a TXT file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read().strip()\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def extract_text_from_json(file_path):\n",
    "    \"\"\"Extracts text from a JSON file by flattening its values.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        return json.dumps(data, indent=2)  # Convert JSON structure into readable text\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def deal_file_url(url, file_type):\n",
    "    \"\"\"Processes a URL, extracts text, and returns a RAG-compatible JSON dictionary.\"\"\"\n",
    "    text = None\n",
    "\n",
    "    # Directly extract HTML text without downloading\n",
    "    if file_type == \"html\":\n",
    "        text = extract_text_from_html(url)\n",
    "\n",
    "    else:\n",
    "        # Download the file first\n",
    "        file_path = download_file(url)\n",
    "        if not file_path:\n",
    "            return None\n",
    "        \n",
    "\n",
    "        # Extract text based on file type\n",
    "        if file_type == \"pdf\":\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "        elif file_type == \"docx\":\n",
    "            text = extract_text_from_docx(file_path)\n",
    "        elif file_type == \"excel\":\n",
    "            text = extract_text_from_excel(file_path)\n",
    "        elif file_type == \"plaintext\":\n",
    "            text = extract_text_from_plaintext(file_path)\n",
    "        elif file_type == \"json\":\n",
    "            text = extract_text_from_json(file_path)\n",
    "\n",
    "    if not text:\n",
    "        return None  # Return None if text extraction failed\n",
    "\n",
    "    # Format JSON entry for RAG\n",
    "    json_entry = {\n",
    "        \"id\": os.path.basename(urlparse(url).path).split(\".\")[0],\n",
    "        \"url\": url,\n",
    "        \"title\": os.path.basename(urlparse(url).path),\n",
    "        \"file_type\": file_type,\n",
    "        \"content\": text\n",
    "    }\n",
    "\n",
    "    return json_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Remove extra spaces, newlines, and unwanted characters.\"\"\"\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(r\"\\[.*?\\]\", \"\", text)  # Remove references like [1]\n",
    "    return text\n",
    "\n",
    "def filter_links(links, base_url):\n",
    "    base_domain = urlparse(base_url).netloc\n",
    "\n",
    "    # Convert relative links to absolute URLs\n",
    "    absolute_links = [urljoin(base_url, link) for link in links]\n",
    "\n",
    "    useful_links = []\n",
    "    for link in absolute_links:\n",
    "        parsed_link = urlparse(link)\n",
    "        netloc = parsed_link.netloc\n",
    "        path = parsed_link.path.lower()\n",
    "\n",
    "        # ✅ Remove external links\n",
    "        if netloc != base_domain:\n",
    "            continue\n",
    "\n",
    "        # ✅ Remove unwanted navigation and UI links\n",
    "        unwanted_keywords = [\n",
    "            \"login\", \"signup\", \"account\", \"profile\", \"settings\", \"cart\", \"terms\", \"privacy\",\n",
    "            \"help\", \"contact\", \"about\", \"faq\"\n",
    "        ]\n",
    "        if any(word in path for word in unwanted_keywords):\n",
    "            continue\n",
    "\n",
    "        # ✅ Remove JavaScript, email, and phone links\n",
    "        if link.startswith((\"javascript:\", \"mailto:\", \"tel:\")):\n",
    "            continue\n",
    "\n",
    "        # ✅ Remove pagination links\n",
    "        if \"page=\" in path or \"offset=\" in path:\n",
    "            continue\n",
    "\n",
    "        # ✅ Remove tracking, ad, and referral links\n",
    "        if any(param in link for param in [\"utm_\", \"ref=\", \"tracking\"]):\n",
    "            continue\n",
    "\n",
    "        useful_links.append(link)\n",
    "    \n",
    "    return useful_links\n",
    "\n",
    "def check_valid_links(url):\n",
    "    try:\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        response = requests.head(url, headers=headers, timeout=5, allow_redirects=True)\n",
    "\n",
    "        # Extract Content-Type from headers\n",
    "        content_type = response.headers.get(\"Content-Type\", \"\").lower()\n",
    "\n",
    "        if \"text/html\" in content_type:\n",
    "            return \"Web\"\n",
    "        \n",
    "        if \"text/html\" in content_type:\n",
    "            return \"html\"\n",
    "        elif \"application/json\" in content_type:\n",
    "            return \"json\"\n",
    "        elif \"application/pdf\" in content_type:\n",
    "            return \"pdf\"\n",
    "        elif \"application/msword\" in content_type or \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\" in content_type:\n",
    "            return \"docx\"\n",
    "        elif \"application/vnd.ms-excel\" in content_type or \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\" in content_type:\n",
    "            return \"excel\"\n",
    "        elif \"text/plain\" in content_type:\n",
    "            return \"plaintext\"\n",
    "\n",
    "        return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error checking URL: {url} - {e}\")\n",
    "        return None\n",
    "    \n",
    "def extract_website_content(url):\n",
    "    \"\"\"Fetch and parse content from a webpage, then convert it into a structured JSON entry.\"\"\"\n",
    "\n",
    "    headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch {url}, status code: {response.status_code}\")\n",
    "        return {}, []\n",
    "    \n",
    "    link_type = check_valid_links(url)\n",
    "\n",
    "\n",
    "    if not link_type:\n",
    "        return {}, []\n",
    "\n",
    "    if link_type != \"Web\":\n",
    "        print(f'File url: {url}')\n",
    "        return deal_file_url(url, link_type), []\n",
    "\n",
    "    try:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(response)\n",
    "        print(url)\n",
    "        print(response.text)\n",
    "\n",
    "    # Extract title\n",
    "    title = soup.title.text if soup.title else \"No Title Found\"\n",
    "\n",
    "    # Extract main content (paragraphs)\n",
    "    paragraphs = [p.get_text(strip=True) for p in soup.find_all(\"p\")]\n",
    "    content = clean_text(\"\\n\".join(paragraphs))\n",
    "    \n",
    "    # Extract keywords (based on meta tags)\n",
    "    meta_keywords = soup.find(\"meta\", {\"name\": \"keywords\"})\n",
    "    keywords = meta_keywords[\"content\"].split(\",\") if meta_keywords else []\n",
    "    links = filter_links([a[\"href\"] for a in soup.find_all(\"a\", href=True)], url)\n",
    "\n",
    "    # Build JSON entry\n",
    "    json_entry = {\n",
    "        \"url\": url,\n",
    "        \"title\": title,\n",
    "        \"content\": content,\n",
    "        \"keywords\": keywords\n",
    "    }\n",
    "\n",
    "\n",
    "    return json_entry, links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFS_links_web(base_url, visited):\n",
    "    web_dicts = []\n",
    "\n",
    "    links_to_visit = [base_url]\n",
    "\n",
    "    while len(links_to_visit)> 0:\n",
    "        url = links_to_visit.pop(0)\n",
    "\n",
    "        if url in visited:\n",
    "            continue\n",
    "\n",
    "        if len(visited)%100 == 0:\n",
    "            print(len(visited))\n",
    "            \n",
    "        visited.add(url)\n",
    "\n",
    "        json_entry, links = extract_website_content(url)\n",
    "        if not json_entry or  len(json_entry) == 0:\n",
    "            continue\n",
    "\n",
    "        links_to_visit.extend(links)\n",
    "\n",
    "        web_dicts.append(json_entry)\n",
    "\n",
    "    return web_dicts, visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.heinzhistorycenter.org/\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "Failed to fetch https://www.heinzhistorycenter.org/?page_id=1533, status code: 404\n",
      "Failed to fetch https://www.heinzhistorycenter.org/?page_id=1542, status code: 404\n",
      "400\n",
      "500\n",
      "Failed to fetch https://www.heinzhistorycenter.org/wp-content/uploads/2022/10/Time-Capsule_World's-Fair.mp3, status code: 404\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "File url: https://www.heinzhistorycenter.org/wp-content/uploads/2023/10/HHC-Reproductions-Permissions.pdf\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.heinzhistorycenter.org/\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(url)\n\u001b[0;32m---> 20\u001b[0m     results, visited \u001b[38;5;241m=\u001b[39m \u001b[43mBFS_links_web\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisited\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     web_pages\u001b[38;5;241m.\u001b[39mextend(results)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# extract_website_content(url)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[30], line 18\u001b[0m, in \u001b[0;36mBFS_links_web\u001b[0;34m(base_url, visited)\u001b[0m\n\u001b[1;32m     15\u001b[0m visited\u001b[38;5;241m.\u001b[39madd(url)\n\u001b[1;32m     17\u001b[0m json_entry, links \u001b[38;5;241m=\u001b[39m extract_website_content(url)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(json_entry) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     21\u001b[0m links_to_visit\u001b[38;5;241m.\u001b[39mextend(links)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "url = \"https://www.pittsburghsymphony.org/\" # 403\n",
    "url = \"https://pittsburghopera.org/\" # Yes\n",
    "url = \"https://trustarts.org/\" #403\n",
    "url = \"https://carnegiemuseums.org/\" # Yes\n",
    "url = \"https://www.heinzhistorycenter.org/\" # Yes\n",
    "url = \"https://www.thefrickpittsburgh.org/\" # Yes\n",
    "url = \"https://www.visitpittsburgh.com/events-festivals/food-festivals/\" # Yes\n",
    "url = \"https://www.picklesburgh.com/\" # Yes\n",
    "url = \"https://www.pghtacofest.com/\" # Yes\n",
    "url = \"https://pittsburghrestaurantweek.com/\"\n",
    "url = \"https://littleitalydays.com/\"\n",
    "url = \"https://bananasplitfest.com/\"\n",
    "\n",
    "visited = set()\n",
    "\n",
    "web_pages = []\n",
    "\n",
    "for url in [\"https://www.heinzhistorycenter.org/\"]:\n",
    "    print(url)\n",
    "    results, visited = BFS_links_web(url, visited)\n",
    "    web_pages.extend(results)\n",
    "\n",
    "# extract_website_content(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'pdfplumber' is not defined\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.heinzhistorycenter.org/wp-content/uploads/2022/10/Time-Capsule_Unconquered.mp3'\n",
    "\n",
    "url = 'https://www.heinzhistorycenter.org/wp-content/uploads/2023/10/HHC-Reproductions-Permissions.pdf'\n",
    "\n",
    "\n",
    "extract_text_from_pdf(\"downloaded_files/HHC-Reproductions-Permissions.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python python3",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
